{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5g6T5_BOLGx"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install tiktoken\n",
        "!pip install openai  # For OpenAI models like GPT\n",
        "!pip install chromadb\n",
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New"
      ],
      "metadata": {
        "id": "QvYzn0heVxEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langchain dependencies\n",
        "from langchain.document_loaders.pdf import PyPDFDirectoryLoader  # Importing PDF loader from Langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Importing text splitter from Langchain\n",
        "from langchain.embeddings import OpenAIEmbeddings  # Importing OpenAI embeddings from Langchain\n",
        "from langchain.schema import Document  # Importing Document schema from Langchain\n",
        "from langchain.vectorstores.chroma import Chroma  # Importing Chroma vector store from Langchain\n",
        "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders.text import TextLoader\n",
        "\n",
        "\n",
        "import os  # Importing os module for operating system functionalities\n",
        "import shutil  # Importing shutil module for high-level file operations"
      ],
      "metadata": {
        "id": "3A3CPjx7TxGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to your pdf files:\n",
        "DATA_PATH = r\"files\"\n",
        "def load_documents():\n",
        "    \"\"\"\n",
        "    Load PDF documents from the specified directory using PyPDFDirectoryLoader.\n",
        "\n",
        "    Returns:\n",
        "        List of Document objects: Loaded PDF documents represented as Langchain Document objects.\n",
        "    \"\"\"\n",
        "    document_loader = DirectoryLoader(DATA_PATH)  # Initialize PDF loader with specified directory\n",
        "    return document_loader.load()  # Load PDF documents and return them as a list of Document objects"
      ],
      "metadata": {
        "id": "2t9K9nxTVufe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_documents()\n",
        "print(documents)"
      ],
      "metadata": {
        "id": "_LrIXMlXVzty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)\n"
      ],
      "metadata": {
        "id": "WGs3BYKzV3d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(documents: list[Document]):\n",
        "    \"\"\"\n",
        "    Split the text content of the given list of Document objects into smaller chunks.\n",
        "\n",
        "    Args:\n",
        "        documents (list[Document]): List of Document objects containing text content to split.\n",
        "\n",
        "    Returns:\n",
        "        list[Document]: List of Document objects representing the split text chunks.\n",
        "    \"\"\"\n",
        "    # Initialize text splitter with specified parameters\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=400,  # Size of each chunk in characters\n",
        "        chunk_overlap=100,  # Overlap between consecutive chunks\n",
        "        length_function=len,  # Function to compute the length of the text\n",
        "        add_start_index=True,  # Flag to add start index to each chunk\n",
        "    )\n",
        "    # Split documents into smaller chunks using text splitter\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
        "\n",
        "    # Print example of page content and metadata for a chunk\n",
        "    document = chunks[10]\n",
        "    print(document.page_content)\n",
        "    print(document.metadata)\n",
        "\n",
        "    return chunks  # Return the list of split text chunks"
      ],
      "metadata": {
        "id": "Gv-Qbl9iWncV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = split_text(documents)"
      ],
      "metadata": {
        "id": "vluUY4_mWpwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chunks:\n",
        "    print(chunk)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "R3MsuUPoWqzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMA_PATH = \"chroma\"\n"
      ],
      "metadata": {
        "id": "lcOJBQtcW0GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_chroma(chunks: list[Document]):\n",
        "    # Clear out the database first.\n",
        "    if os.path.exists(CHROMA_PATH):\n",
        "        shutil.rmtree(CHROMA_PATH)\n",
        "\n",
        "    # print(chunks)\n",
        "\n",
        "    # Create a new DB from the documents.\n",
        "    db = Chroma.from_documents(\n",
        "        chunks, OpenAIEmbeddings(openai_api_key='****'), persist_directory=CHROMA_PATH\n",
        "    )\n",
        "    db.persist()\n",
        "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
      ],
      "metadata": {
        "id": "WQcxpGZBW6W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_store():\n",
        "    \"\"\"\n",
        "    Function to generate vector database in chroma from documents.\n",
        "    \"\"\"\n",
        "    documents = load_documents()  # Load documents from a source\n",
        "    chunks = split_text(documents)  # Split documents into manageable chunks\n",
        "    save_to_chroma(chunks)  # Save the processed data to a data store"
      ],
      "metadata": {
        "id": "IFW2zAbcXBHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "# Generate the data store\n",
        "generate_data_store()"
      ],
      "metadata": {
        "id": "rOgbXOasW8a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"which tablets do you have\"\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "laJOAW2nW-cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use same embedding function as before\n",
        "embedding_function = OpenAIEmbeddings(openai_api_key='')\n",
        "\n",
        "# Prepare the database\n",
        "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
        "\n",
        "# Search the DB.\n",
        "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
        "if len(results) == 0 or results[0][1] < 0.5:\n",
        "    print(f\"Unable to find matching results.\")"
      ],
      "metadata": {
        "id": "wjgNzFHKXolk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "9SEK8WE5Xwzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n"
      ],
      "metadata": {
        "id": "onaYjcHzYAQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
        "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "HCjODVDxYFIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(openai_api_key='*************************')\n",
        "response_text = model.predict(prompt)\n",
        "\n",
        "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
        "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
        "print(formatted_response)"
      ],
      "metadata": {
        "id": "I-o5J-RTYGwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text"
      ],
      "metadata": {
        "id": "HWSwUWz7YRbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bdT8me9IYWz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}